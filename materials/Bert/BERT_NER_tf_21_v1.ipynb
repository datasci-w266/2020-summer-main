{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1><center>A Simple Named Entity Recognition Model using  BERT  and Keras</center></h1>\n",
    "<h4><center>Initially prepared for UC Berkeley MIDS - W266</center></h4>\n",
    "\n",
    "\n",
    "<h3><center>SUMMARY</center></h3>\n",
    "\n",
    "In this notebook we investigate how we can leverage BERT (see [\"BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding\"](https://arxiv.org/pdf/1810.04805.pdf), by Devlin/Chang/Lee/Toutanova, Google AI Language) for the problem of Named Entity Recognition (NER). Their paper actually contains the NER use case as a fine-tuning example, but we are not striving to replicate necessarily exactly their approach but build the model in the most approachable and 'naive' way, i.e. simply applying a straightforward model that follows intuitively the BERT mantra leveraging its context-based embeddings.\n",
    "\n",
    "\n",
    "We look at the effect of also fine-tuning BERT layers vs just adding and training classification layers on top of the BERT model and find that in this cursory and certainly incomplete study the re-training of BERT layers does offer some advantages. We also perform a test reducing the training data by 90% and find that the results are still quite decent, re-emphasizing BERT's usefulness in situations where the data set is on the small side.  \n",
    "\n",
    "\n",
    "## Table of Contents\n",
    "\n",
    "I. [Introduction & Approach](#ia)   \n",
    "1. [Introduction](#intro)  \n",
    "2. [Problem Definition & Metrics](#problem)  \n",
    "3. [Notebook Strategy](#strategy)  \n",
    "\n",
    "\n",
    "II. [Setup](#setup)   \n",
    "1. [Data](#data)  \n",
    "2. [BERT](#bert)  \n",
    "3. [Getting Started](#start)  \n",
    "\n",
    "\n",
    "III. [Data Preprocessing](#preprocess)   \n",
    "1. [BERT Tokenizer](#tokenizer)  \n",
    "2. [Extraction](#extract)  \n",
    "3. [Initial Data Analysis](#analysis) \n",
    "4. [Baseline: Always picking 'Other'](#baseline) \n",
    "5. [Train/Test Split](#split)  \n",
    "\n",
    "IV. [The Model](#model)   \n",
    "1. [Custom Loss & Accuracy](#custom)  \n",
    "2. [BERT Layer](#bert_layer)  \n",
    "2. [Model Construction](#ner_model) \n",
    "\n",
    "\n",
    "V. [Model Runs/Experiments](#runs)   \n",
    "1. [With BERT-layer Fine-Tuning](#retrain)  \n",
    "2. [Predictions & Confusion Matrix](#confusion)  \n",
    "3. [Without BERT-Layer Fine-Tuning](#basic)  \n",
    "4. [A 90%-Reduced Training Set](#tiny)  \n",
    "\n",
    "\n",
    "VI. [Summary](#summary)   \n",
    "\n",
    "\n",
    "\n",
    "## I. Introduction & Approach <a id=\"ia\" />\n",
    "\n",
    "### I. Introduction & Strategy <a id=\"intro\" />\n",
    "\n",
    "BERT and other context-aware embedding frameworks like [ELMO](https://arxiv.org/abs/1802.05365), OpenAI's [GPT-2](https://d4mucfpksywv.cloudfront.net/better-language-models/language_models_are_unsupervised_multitask_learners.pdf), and [XLNet](https://arxiv.org/pdf/1906.08237.pdf), etc.  -  provide extremely useful basis for many NLP tasks. A key reason why these frameworks are so useful is that they allow us to use the power of extensive pre-training that was done on a (set of) large corpus/era. \n",
    "\n",
    "More specifically, their ability to encode deep contextual relationships between words (and sentences or sentence segments) derived from a generic set of tasks provides us with the context-specific embeddings.  Depending on the task, we can then simply add a couple of classification layers with a modest number of weights to fine-tune the combined model to our very specific NLP task that may not have the luxury of a very large labeled data set.\n",
    "\n",
    "There are numerous and very good resources available on the web for various of these tasks (Movie Reviews, Sentiment  Analysis, etc,.). In this notebook, we want to consider the task of Named Entity Recognition, as it features a number of useful complexities that are good to discuss:\n",
    "\n",
    "* token-level vs. sentence-level BERT output, which seems to be less-often discussed \n",
    "* potential one-to-many split of word-to-token by the tokenizer (what are we going to do for the labels?) \n",
    "* potentially a need for custom loss and accuracy definitions\n",
    "\n",
    "Conceptually, we will follow the original BERT paper in its approach to NER:\n",
    "\n",
    "<img src=\"BERT_NER_Devlin_et_al.png\" alt=\"Drawing\" style=\"width: 600px;\"/>\n",
    "<center>Image Source: \"BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding\"</center>\n",
    "\n",
    "Each word will need to be tokenized. We will then, sentence-by-sentence, feed in the tokenized text into BERT, resulting in our case (we are using the BERT's base model) in a 768-dimensional output vector for each input token (and other tokens that BERT wants us to add). We then simply add a fully-connected hidden layer and finally a classification of suitable dimension that will take each token-output and make a decision on its NER label.  \n",
    "\n",
    "\n",
    "This is very intuitive. However, a few obvious questions arise that we want to look at in this notebook:\n",
    "\n",
    "1) How do we need to pre-process the data set to be suitable for BERT?   \n",
    "3) How can we build the model in Keras?   \n",
    "4) How can we incorporate custom loss functions and accuracy calculations?   \n",
    "5) What does fine-tuning mean? Is it just adding and training new layer(s), or do I re-train BERT layers as well?   \n",
    "6) Do I need to worry about customizing the optimizer?  \n",
    "\n",
    "These and other questions we hope to be able to shed some light on. The dataset we will be using is the \"**Annotated Corpus for Named Entity Recognition using GMB [Groningen Meaning Bank]**\", which is shared on [Kaggle](https://www.kaggle.com/abhinavwalia95/entity-annotated-corpus). It contains sentences with 1m+ words, conveniently annotated with POS and NER tags. \n",
    "\n",
    "### I.2. Problem Definition & Metrics <a id=\"problem\" />\n",
    "\n",
    "Our task will obviously be to properly identify the NER tags. There are potentially two things to consider when we want to define our success metrics: \n",
    "\n",
    "1) If we send the data sentence-by-sentence, we will need to apply padding to ensure consistent length. This will create 'new' labels that we will call 'nerPad'. Also, words can be split into multiple tokens, requiring us to add filler labels, which we will denote 'nerX'.  (There are multiple ways to address this, but this is what we are choosing here.)\n",
    "\n",
    "If we do that, should we look at accuracy over all tokens? Probably not. So our **first metric will be: accuracy for tokens which were part of the original text (and only the first token if a word is split)**.\n",
    "\n",
    "2) As we know from NER problems, most tokens will be 'Other'. So we may get already a pretty decent baseline result by always predicting 'Other'. In situations like that it may be useful to also look at **our second metric: the accuracy for all original tokens that are not 'Other'**.\n",
    "\n",
    "\n",
    "### I.3. Notebook Strategy <a id=\"strategy\" />\n",
    "\n",
    "The outline that we will follow in this notebook is this:\n",
    "\n",
    "**1) Process the text**\n",
    "* re-assemble words into sentences. (The corpus is of the form one-line-one-word, with sentence markers.)\n",
    "* tokenize the sentences with the BERT Tokenizer\n",
    "* create the input ids required for BERT:\n",
    "   * **sentence_ids** [the list of token ids for each sentence]\n",
    "   * **mask_ids** [the specification whether a specific token should be masked out (we mask out '[PAD]' tokens)]\n",
    "   * **sequence_ids** [used to denote whether a token is part of the first, second, or other segment in each input example. For us, this will always be '0'.]\n",
    "* prepare the labels  \n",
    "\n",
    "Some complications can include:\n",
    "- some words may not be in vocab\n",
    "- words can get split into multiple tokens. What are the labels?\n",
    "- Sentences do not all have the same length. Padding!\n",
    "- usual formatting details, like \"10,000\" and \"\"\" for quotes in this case.\n",
    "\n",
    "**2) Analyze and prepare the data**\n",
    "* Identify balance/imbalance situation\n",
    "* Estimate baseline accuracy defined by 'always picking the most common token'\n",
    "* Split into training and test set\n",
    "\n",
    "**3) Build the model**\n",
    "* Build BERT layer\n",
    "* Add classification layer(s)\n",
    "* Define custom loss functions and metrics\n",
    "\n",
    "**4) Run a few experiments**\n",
    "* Allow for re-training of a few BERT layers\n",
    "* Investigate the confusion matrix\n",
    "* Compare results with the model without re-training BERT layers\n",
    "* Test how good the results would be if you only at 10% of the training data (~4k sentences) \n",
    "\n",
    "\n",
    "This notebook leverages (obviously) BERT from Hugging Face (https://huggingface.co/transformers/model_doc/bert.html#tfbertmodel).  \n",
    "\n",
    "The notebook was run with **Tensorflow 2.1** leveraging one GPU with 4 GB of memory. \n",
    "\n",
    "\n",
    "\n",
    "## II. Setup & Strategy\n",
    "\n",
    "### II.1. Data<a id=\"data\" />\n",
    "\n",
    "First, obtain the dataset (\"**Annotated Corpus for Named Entity Recognition using GMB [Groningen Meaning Bank]**\", which is shared on [Kaggle](https://www.kaggle.com/abhinavwalia95/entity-annotated-corpus). The ner_dataset.csv file is the relevant file.\n",
    "\n",
    "Let us take a quick peek at the file:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ",.,.,O\r",
      "\r\n",
      "Sentence: 47958,They,PRP,O\r",
      "\r\n",
      ",say,VBP,O\r",
      "\r\n",
      ",not,RB,O\r",
      "\r\n",
      ",all,DT,O\r",
      "\r\n",
      ",of,IN,O\r",
      "\r\n",
      ",the,DT,O\r",
      "\r\n",
      ",rockets,NNS,O\r",
      "\r\n",
      ",exploded,VBD,O\r",
      "\r\n",
      ",upon,IN,O\r",
      "\r\n",
      ",impact,NN,O\r",
      "\r\n",
      ",.,.,O\r",
      "\r\n",
      "Sentence: 47959,Indian,JJ,B-gpe\r",
      "\r\n",
      ",forces,NNS,O\r",
      "\r\n",
      ",said,VBD,O\r",
      "\r\n",
      ",they,PRP,O\r",
      "\r\n",
      ",responded,VBD,O\r",
      "\r\n",
      ",to,TO,O\r",
      "\r\n",
      ",the,DT,O\r",
      "\r\n",
      ",attack,NN,O\r",
      "\r\n"
     ]
    }
   ],
   "source": [
    "!tail -20 'ner_dataset.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see the words line-by-line, the labels (POS and NER), and the sentence boundaries. Perfect."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### II.2. Imports:  <a id=\"bert\" />\n",
    "\n",
    "We will use the cased base BERT implementation from Hugging Face (https://huggingface.co/transformers/model_doc/bert.html#tfbertmodel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "import tensorflow as tf\n",
    "from time import time\n",
    "import io\n",
    "import re\n",
    "from csv import reader\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import colors\n",
    "from matplotlib.ticker import PercentFormatter\n",
    "\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.backend import sparse_categorical_crossentropy\n",
    "from tensorflow.keras.layers import Dense, Flatten\n",
    "\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BERT is easily imported from **Hugging Face's transformer library**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer, TFBertModel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So the two components we need are the **model** and the **tokenizer**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define some key parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = './'  # path to ner_dataset.csv file , from \n",
    "\n",
    "now = datetime.now() # current date and time\n",
    "\n",
    "# make sure that the paths are accessible within the notebook\n",
    "sys.path.insert(0,data_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obviously, we will need to do quite a bit of pre-processing. BERT - as well as NER in general - requires us to process the text in a larger context, which suggests that we should send the data to BERT sentence-by-sentence. (An alternative would also be to just chunk up the text, irrespective of sentence boundaries.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## III. Data Preprocessing <a id=\"preprocess\" />\n",
    "\n",
    "### III.1 BERT Tokenizer<a id=\"tokenizer\" />\n",
    "\n",
    "We need to define the tokenizer. BERT has its own and that is the one that should be used. As it is specific to the (pre-trained) model, we need to specify it. For obvious reasons we will use the 'cased'  model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-cased')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's play with the tokenizer. You will see that the tokenizer occasionally splits one word into multiple tokens. Why is that the case? Because the approach of using word pieces reduces the vocabulary size and/or number of unknown words.\n",
    "\n",
    "Here is one example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I', \"'\", 'll', 'learn', 'to', 'swim', 'in', '123', '##42', 'years', '.']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.tokenize('I\\'ll learn to swim in 12342 years.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note how the \"I'll\" phrase and the number '12342' got split. This already highlights an area one needs to address: splitting of tokens will need to be accounted for in the labeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[101, 178, 112, 1325, 3858, 1106, 11231, 1107, 13414, 23117, 1201, 119]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.convert_tokens_to_ids([\n",
    "    '[CLS]', 'i', \"'\",'ll', 'learn','to','swim','in','123', '##42', 'years', '.'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Faye']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.convert_ids_to_tokens([20958])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Good. Now we are ready to use it for our text."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### III.2. Extraction<a id=\"extract\"/>\n",
    "\n",
    "\n",
    "We have seen above how the data set looks. We can now turn to the pre-processing and creating the input for BERT. Specifically, we need to:\n",
    "\n",
    "1) Tokenize the sentences. Note again that one word can be split into multiple tokens, and we need to insert custom labels when that happens to make sure we don't mess up the alignment. We choose a new 'nerX' label here.\n",
    "\n",
    "2) Create BERT tokens and add [CLS], [PAD], etc.\n",
    "\n",
    "3) Convert these tokens into ids, also via the tokenizer. These qill create the sentence_ids.\n",
    "\n",
    "4) Create the mask ids. Mask out all of the padding tokens.\n",
    "\n",
    "5) Create the sequence ids. In our case, they are all '0' as we do not compare or even have multiple sentences in one example.\n",
    "\n",
    "To do this, we first define a helper function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def addWord(word, pos, ner):\n",
    "    \"\"\"\n",
    "    Convert a word into a word token and add supplied NER and POS labels. Note that the word can be  \n",
    "    tokenized to two or more tokens. Correspondingly, we add - for now - custom 'X' tokens to the labels in order to \n",
    "    maintain the 1:1 mappings between word tokens and labels.\n",
    "    \n",
    "    arguments: word, pos label, ner label\n",
    "    returns: dictionary with tokens and labels\n",
    "    \"\"\"\n",
    "    # the dataset contains various '\"\"\"' combinations which we choose to truncate to '\"', etc. \n",
    "    if word == '\"\"\"\"':\n",
    "        word = '\"'\n",
    "    elif word == '``':\n",
    "        word = '`'\n",
    "        \n",
    "    tokens = tokenizer.tokenize(word)\n",
    "    tokenLength = len(tokens)      # find number of tokens corresponfing to word to later add 'X' tokens to labels\n",
    "    \n",
    "    addDict = dict()\n",
    "    \n",
    "    addDict['wordToken'] = tokens\n",
    "    addDict['posToken'] = [pos] + ['posX'] * (tokenLength - 1)\n",
    "    addDict['nerToken'] = [ner] + ['nerX'] * (tokenLength - 1)\n",
    "    addDict['tokenLength'] = tokenLength\n",
    "    \n",
    "    \n",
    "    return addDict\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see what it does:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'wordToken': ['protest'],\n",
       " 'posToken': ['VB'],\n",
       " 'nerToken': ['O'],\n",
       " 'tokenLength': 1}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "addWord('protest', 'VB', 'O')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'wordToken': ['Iraq'],\n",
       " 'posToken': ['NNP'],\n",
       " 'nerToken': ['B-geo'],\n",
       " 'tokenLength': 1}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "addWord('Iraq', 'NNP', 'B-geo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'wordToken': ['1000', '##0'],\n",
       " 'posToken': ['CD', 'posX'],\n",
       " 'nerToken': ['O', 'nerX'],\n",
       " 'tokenLength': 2}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "addWord('10000', 'CD', 'O')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are now ready to convert the text file into appropriate arrays. First, we need to define the length of each example. For this we will define the hyper-parameter max_length. All sentences longer (post-tokenization!) than this parameter will be clipped off, and all sentences that are shorter will be padded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_length = 30"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example creation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Read the file line by line and construct sentences. A sentence end is marked by the word 'sentence' in the next row.\n",
    "You need to take care of that. Also, you need to cap sentence length using max_length. Sentences which are shorter than \n",
    "max_length need to be padded. Also, we choose to end all sentences with a [SEP] token, padded or not. \n",
    "\"\"\"\n",
    "\n",
    "with io.open(data_path + 'ner_dataset.csv', 'r', encoding='utf-8', errors='ignore') as train:\n",
    "    text = train.readlines()\n",
    "\n",
    "\n",
    "# lists for sentences, tokens, labels, etc.  \n",
    "sentenceList = []\n",
    "sentenceTokenList = []\n",
    "posTokenList = []\n",
    "nerTokenList = []\n",
    "sentLengthList = []\n",
    "\n",
    "# lists for BERT input\n",
    "bertSentenceIDs = []\n",
    "bertMasks = []\n",
    "bertSequenceIDs = []\n",
    "\n",
    "sentence = ''\n",
    "\n",
    "# always start with [CLS] tokens\n",
    "sentenceTokens = ['[CLS]']\n",
    "posTokens = ['[posCLS]']\n",
    "nerTokens = ['[nerCLS]']\n",
    "\n",
    "for line in text:\n",
    "    \n",
    "    cleanLine = re.sub(r'(?!(([^\"]*\"){2})*[^\"]*$),', '', line)  # deal with '\"10,000\"' and convert them to '10000' \n",
    "\n",
    "    sent, word, pos, ner = cleanLine.split(',')\n",
    "    \n",
    "    ner = ner[:-1]   # remove DOS token\n",
    "    \n",
    "    # if new sentence starts\n",
    "    if (sent[:8] == 'Sentence'):            \n",
    "            \n",
    "        sentenceLength = min(max_length -1, len(sentenceTokens))\n",
    "        sentLengthList.append(sentenceLength)\n",
    "        \n",
    "                    \n",
    "        # Create space for at least a final '[SEP]' token\n",
    "        if sentenceLength >= max_length - 1: \n",
    "            sentenceTokens = sentenceTokens[:max_length - 2]\n",
    "            posTokens = posTokens[:max_length - 2]\n",
    "            nerTokens = nerTokens[:max_length - 2]\n",
    "\n",
    "        # add a ['SEP'] token and padding\n",
    "        \n",
    "        sentenceTokens += ['[SEP]'] + ['[PAD]'] * (max_length -1 - len(sentenceTokens))\n",
    "        \n",
    "        posTokens += ['[posSEP]'] + ['[posPAD]'] * (max_length - 1 - len(posTokens) )\n",
    "        nerTokens += ['[nerSEP]'] + ['[nerPAD]'] * (max_length - 1 - len(nerTokens) )\n",
    "            \n",
    "        sentenceList.append(sentence)\n",
    "\n",
    "        sentenceTokenList.append(sentenceTokens)\n",
    "\n",
    "        bertSentenceIDs.append(tokenizer.convert_tokens_to_ids(sentenceTokens))\n",
    "        bertMasks.append([1] * (sentenceLength + 1) + [0] * (max_length -1 - sentenceLength ))\n",
    "        bertSequenceIDs.append([0] * (max_length))\n",
    "                             \n",
    "        posTokenList.append(posTokens)\n",
    "        nerTokenList.append(nerTokens)\n",
    "        \n",
    "        sentence = ''\n",
    "        sentenceTokens = ['[CLS]']\n",
    "        posTokens = ['[posCLS]']\n",
    "        nerTokens = ['[nerCLS]']\n",
    "        \n",
    "        sentence += ' ' + word\n",
    "\n",
    "    addDict = addWord(word, pos, ner)\n",
    "\n",
    "    sentenceTokens += addDict['wordToken']\n",
    "    posTokens += addDict['posToken']\n",
    "    nerTokens += addDict['nerToken']\n",
    "\n",
    "# The first two list elements need to be removed. 1st line in file is a-typical, and 2nd line does not end a sentence   \n",
    "sentLengthList = sentLengthList[2:]\n",
    "sentenceTokenList = sentenceTokenList[2:]\n",
    "bertSentenceIDs = bertSentenceIDs[2:]\n",
    "bertMasks = bertMasks[2:]\n",
    "bertSequenceIDs = bertSequenceIDs[2:]\n",
    "posTokenList = posTokenList[2:]\n",
    "nerTokenList = nerTokenList[2:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What did this do?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[CLS]', 'They', 'marched', 'from', 'the', 'Houses', 'of', 'Parliament', 'to', 'a', 'rally', 'in', 'Hyde', 'Park', '.', '[SEP]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]']\n"
     ]
    }
   ],
   "source": [
    "print(sentenceTokenList[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[nerCLS]', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-geo', 'I-geo', 'O', '[nerSEP]', '[nerPAD]', '[nerPAD]', '[nerPAD]', '[nerPAD]', '[nerPAD]', '[nerPAD]', '[nerPAD]', '[nerPAD]', '[nerPAD]', '[nerPAD]', '[nerPAD]', '[nerPAD]', '[nerPAD]', '[nerPAD]']\n"
     ]
    }
   ],
   "source": [
    "print(nerTokenList[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "print(bertMasks[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This looks right. Everything past the '[SEP]' token, i.e., the '[nerSEP]' label, is masked out. Also the sequence_ids are correct: there is only one sentence, so all ids should have the same value of zero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "print(bertSequenceIDs[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks reasonable. \n",
    "\n",
    "\n",
    "### III.3. Initial Data Analysis<a id=\"analysis\" />\n",
    "\n",
    "It is important to understand the dataset prior to doing any modeling or training. First, what are the length of the original sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1.0000e+00, 2.0000e+00, 3.0000e+00, 1.9000e+01, 1.0600e+02,\n",
       "        1.8400e+02, 3.0800e+02, 4.3000e+02, 5.1900e+02, 6.6700e+02,\n",
       "        8.2800e+02, 9.4000e+02, 1.0040e+03, 1.1560e+03, 1.2590e+03,\n",
       "        1.3620e+03, 1.4480e+03, 1.5610e+03, 1.5710e+03, 1.7080e+03,\n",
       "        1.7600e+03, 1.8350e+03, 1.9350e+03, 1.9450e+03, 1.9120e+03,\n",
       "        1.8550e+03, 1.9040e+03, 1.9736e+04]),\n",
       " array([ 2.        ,  2.96428571,  3.92857143,  4.89285714,  5.85714286,\n",
       "         6.82142857,  7.78571429,  8.75      ,  9.71428571, 10.67857143,\n",
       "        11.64285714, 12.60714286, 13.57142857, 14.53571429, 15.5       ,\n",
       "        16.46428571, 17.42857143, 18.39285714, 19.35714286, 20.32142857,\n",
       "        21.28571429, 22.25      , 23.21428571, 24.17857143, 25.14285714,\n",
       "        26.10714286, 27.07142857, 28.03571429, 29.        ]),\n",
       " <a list of 28 Patch objects>)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sentenceLengths= [l for l in sentLengthList]\n",
    "\n",
    "plt.hist(np.array(sentenceLengths), bins=(max_length-2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An average sentence length of ~25 (incl. extra tokens!) is roughly expected. It turns out that on these types of corpora an average sentence length of ~20 tends to be seen. The big spike on the right obviously corresponds to all sentences that we had to truncate. \n",
    "\n",
    "Next, we analyze the distribution of ner labels. First, we assign numbers to the labels and look at the overall distribution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "numSentences = len(bertSentenceIDs)\n",
    "\n",
    "nerClasses = pd.DataFrame(np.array(nerTokenList).reshape(-1))\n",
    "nerClasses.columns = ['tag']\n",
    "nerClasses.tag = pd.Categorical(nerClasses.tag)\n",
    "nerClasses['cat'] = nerClasses.tag.cat.codes\n",
    "nerClasses['sym'] = nerClasses.tag.cat.codes\n",
    "nerLabels = np.array(nerClasses.cat).reshape(numSentences, -1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[<matplotlib.axes._subplots.AxesSubplot object at 0x7f59bbbe9d50>]],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "nerClasses[['cat']].hist(bins=21)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like a lot of tables with value 16+... Let's see which labels these label numbers corresponds to:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tag</th>\n",
       "      <th>cat</th>\n",
       "      <th>occurences</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B-art</td>\n",
       "      <td>0</td>\n",
       "      <td>345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>B-art</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>B-art</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>B-art</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>B-art</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>436</th>\n",
       "      <td>nerX</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>437</th>\n",
       "      <td>nerX</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>438</th>\n",
       "      <td>nerX</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>439</th>\n",
       "      <td>nerX</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>440</th>\n",
       "      <td>nerX</td>\n",
       "      <td>20</td>\n",
       "      <td>166746</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>441 rows  3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       tag  cat  occurences\n",
       "0    B-art    0         345\n",
       "1    B-art    1           0\n",
       "2    B-art    2           0\n",
       "3    B-art    3           0\n",
       "4    B-art    4           0\n",
       "..     ...  ...         ...\n",
       "436   nerX   16           0\n",
       "437   nerX   17           0\n",
       "438   nerX   18           0\n",
       "439   nerX   19           0\n",
       "440   nerX   20      166746\n",
       "\n",
       "[441 rows x 3 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nerDistribution = (nerClasses.groupby(['tag', 'cat']).agg({'sym':'count'}).reset_index()\n",
    "                   .rename(columns={'sym':'occurences'}))\n",
    "\n",
    "numNerClasses = nerDistribution.tag.nunique()\n",
    "\n",
    "nerDistribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interesting. 16 corresponds to 'O', and all 'extension' labels (i.e., those that were not part of the original data) occur at 17+. \n",
    "\n",
    "'O' is the most common token - by far.\n",
    "\n",
    "### III.4. Baseline: Always picking 'Other'<a id=\"baseline\" />\n",
    "\n",
    "Let's see what a baseline would give for the actual text tokens, if I ALWAYS chose the most common token 'O':"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8432003701378102"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "O_occurences = int(nerDistribution.loc[nerDistribution.tag == 'O','occurences']\\\n",
    "                                .reset_index().drop(['index'], axis=1).loc[16])   # Some gymnasics to get the count..\n",
    "All_occurences = nerDistribution[nerDistribution.cat < 17]['occurences'].sum()\n",
    "\n",
    "O_occurences/All_occurences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So **84.3%** is the baseline to beat for our first metric! Can we do that? We'll see."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### III.5. Train/Test Split and Final Data Preparation<a id=\"split\" />\n",
    "\n",
    "In the last step we need to prepare both labels and input for the model, including the train/test split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_inputs = np.array([bertSentenceIDs, bertMasks, bertSequenceIDs])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now split - in a pretty manual way - the examples into a train and test set. We create a random binary value for each sentence that we use to split train and test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "numSentences = len(bert_inputs[0])\n",
    "np.random.seed(0)\n",
    "training_examples = np.random.binomial(1, 0.7, numSentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainSentence_ids = []\n",
    "trainMasks = []\n",
    "trainSequence_ids = []\n",
    "\n",
    "testSentence_ids = []\n",
    "testMasks = []\n",
    "testSequence_ids = []\n",
    "\n",
    "nerLabels_train =[]\n",
    "nerLabels_test = []\n",
    "\n",
    "\n",
    "for example in range(numSentences):\n",
    "    if training_examples[example] == 1:\n",
    "        trainSentence_ids.append(bert_inputs[0][example])\n",
    "        trainMasks.append(bert_inputs[1][example])\n",
    "        trainSequence_ids.append(bert_inputs[2][example])\n",
    "        nerLabels_train.append(nerLabels[example])\n",
    "    else:\n",
    "        testSentence_ids.append(bert_inputs[0][example])\n",
    "        testMasks.append(bert_inputs[1][example])\n",
    "        testSequence_ids.append(bert_inputs[2][example])\n",
    "        nerLabels_test.append(nerLabels[example])\n",
    "        \n",
    "X_train = np.array([trainSentence_ids,trainMasks,trainSequence_ids])\n",
    "X_test = np.array([testSentence_ids,testMasks,testSequence_ids])\n",
    "\n",
    "nerLabels_train = np.array(nerLabels_train)\n",
    "nerLabels_test = np.array(nerLabels_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  101, 26159,  1104,  8568,  4487,  5067,  1138,  9639,  1194,\n",
       "        1498,  1106,  5641,  1103,  1594,  1107,  5008,  1105,  4555,\n",
       "        1103, 10602,  1104,  1418,  2830,  1121,  1115,  1583,   119,\n",
       "         102,     0,     0])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([17, 16, 16, 16, 20, 20, 16, 16, 16,  2, 16, 16, 16, 16, 16,  2, 16,\n",
       "       16, 16, 16, 16,  3, 16, 16, 16, 16, 16, 19, 18, 18], dtype=int8)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nerLabels_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[CLS]', 'Thousands', 'of', 'demons', '##tra', '##tors', 'have', 'marched', 'through', 'London', 'to', 'protest', 'the', 'war', 'in', 'Iraq', 'and', 'demand', 'the', 'withdrawal', 'of', 'British', 'troops', 'from', 'that', 'country', '.', '[SEP]', '[PAD]', '[PAD]']\n"
     ]
    }
   ],
   "source": [
    "print(sentenceTokenList[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's also get a few train/test positions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 1, 1, 1, 1, 1, 0, 0, 1])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_examples[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the last step, we prepare the actual train and test input and label data. For convenience (quick functionality test on small data set), we introduce parameters k_start & k_end to just use a slide of the full dataset. (Setting k_end to -1 corresponds to using the whole set (as we will do in the following). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use a parameter pair k_start, k_end to look at slices. This helps with quick tests.\n",
    "\n",
    "k_start = 0\n",
    "k_end = -1\n",
    "\n",
    "if k_end == -1:\n",
    "    k_end_train = X_train[0].shape[0]\n",
    "    k_end_test = X_test[0].shape[0]\n",
    "else:\n",
    "    k_end_train = k_end_test = k_end\n",
    "    \n",
    "\n",
    "\n",
    "bert_inputs_train_k = [X_train[0][k_start:k_end_train], X_train[1][k_start:k_end_train], \n",
    "                       X_train[2][k_start:k_end_train]]\n",
    "bert_inputs_test_k = [X_test[0][k_start:k_end_test], X_test[1][k_start:k_end_test], \n",
    "                      X_test[2][k_start:k_end_test]]\n",
    "\n",
    "\n",
    "labels_train_k = nerLabels_train[k_start:k_end_train]\n",
    "labels_test_k = nerLabels_test[k_start:k_end_test]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's it. We are all set to go."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IV. The Model<a id=\"model\"/>\n",
    "\n",
    "### IV.1. Custom Loss & Accuracy<a id=\"custom\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need a **custom loss function** because we only want to optimize for the labels that we actually had in the text, not the extra ones like '[nerPAD]', etc. Our cost function is therefore derived from sparse_categorical_crossentropy, but we choose to modify the function a bit:  we want to mask out all tokens that have a token id larger or equal of 17, corresponding to the extra tokens:  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_loss(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    calculate loss function explicitly, filtering out 'extra inserted labels'\n",
    "    \n",
    "    y_true: Shape: (batch x (max_length + 1) )\n",
    "    y_pred: predictions. Shape: (batch x x (max_length + 1) x num_distinct_ner_tokens ) \n",
    "    \n",
    "    returns:  cost\n",
    "    \"\"\"\n",
    "\n",
    "    #get labels and predictions\n",
    "    \n",
    "    y_label = tf.reshape(Flatten()(tf.cast(y_true, tf.int32)),[-1])\n",
    "    \n",
    "    mask = (y_label < 17)   # This mask is used to remove all tokens that do not correspond to the original base text.\n",
    "\n",
    "    y_label_masked = tf.boolean_mask(y_label, mask)  # mask the labels\n",
    "    \n",
    "    y_flat_pred = tf.reshape(Flatten()(tf.cast(y_pred, tf.float32)),[-1, numNerClasses])\n",
    "    \n",
    "    y_flat_pred_masked = tf.boolean_mask(y_flat_pred, mask) # mask the predictions\n",
    "    \n",
    "    return tf.reduce_mean(sparse_categorical_crossentropy(y_label_masked, y_flat_pred_masked,from_logits=False ))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Does it work as advertised? Let's create a toy example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = tf.constant([[17],[0]])\n",
    "\n",
    "y_pred = tf.constant([\n",
    "    [0.6,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,.4,0,0,0],\n",
    "    [0.6,0.4,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(0.5108274, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "y_true = tf.constant([[17],[0]])\n",
    "\n",
    "y_pred = tf.constant([\n",
    "    [0.0,0,0,0.6,0,0,0,0,0,0,0,0,0,0,0,0,0,.4,0,0,0],\n",
    "    [0.6,0.4,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],\n",
    "])\n",
    "\n",
    "\n",
    "# Nice to have eager execution now...\n",
    "\n",
    "print(custom_loss(y_true, y_pred))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare this to the manual calculation of $-\\log((y^1_{pred})_0)$ (remember that $y^0$ is masked out because the true label is 17) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5108256237659907"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "-np.log(0.6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So this is correct! The position where the true label is 17 is ignored because of the mask!\n",
    "\n",
    "In a similar vein, we define and test a **custom accuracy** calculation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_acc_orig_tokens(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    calculate loss dfunction filtering out also the newly inserted labels\n",
    "    \n",
    "    y_true: Shape: (batch x (max_length) )\n",
    "    y_pred: predictions. Shape: (batch x x (max_length + 1) x num_distinct_ner_tokens ) \n",
    "    \n",
    "    returns: accuracy\n",
    "    \"\"\"\n",
    "\n",
    "    #get labels and predictions\n",
    "    \n",
    "    y_label = tf.reshape(tf.keras.layers.Flatten()(tf.cast(y_true, tf.int64)),[-1])\n",
    "    \n",
    "    mask = (y_label < 17)\n",
    "    y_label_masked = tf.boolean_mask(y_label, mask)\n",
    "    \n",
    "    y_predicted = tf.math.argmax(input = tf.reshape(tf.keras.layers.Flatten()(tf.cast(y_pred, tf.float64)),\\\n",
    "                                                    [-1, numNerClasses]), axis=1)\n",
    "    \n",
    "    y_predicted_masked = tf.boolean_mask(y_predicted, mask)\n",
    "\n",
    "    return tf.reduce_mean(tf.cast(tf.equal(y_predicted_masked,y_label_masked) , dtype=tf.float64))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us also define another accuracy calculation that only looks at the non-Other labels: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_acc_orig_non_other_tokens(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    calculate loss dfunction explicitly filtering out also the 'Other'- labels\n",
    "    \n",
    "    y_true: Shape: (batch x (max_length) )\n",
    "    y_pred: predictions. Shape: (batch x x (max_length + 1) x num_distinct_ner_tokens ) \n",
    "    \n",
    "    returns: accuracy\n",
    "    \"\"\"\n",
    "\n",
    "    #get labels and predictions\n",
    "    \n",
    "    y_label = tf.reshape(tf.keras.layers.Flatten()(tf.cast(y_true, tf.int64)),[-1])\n",
    "    \n",
    "    mask = (y_label < 16)\n",
    "    y_label_masked = tf.boolean_mask(y_label, mask)\n",
    "    \n",
    "    y_predicted = tf.math.argmax(input = tf.reshape(tf.keras.layers.Flatten()(tf.cast(y_pred, tf.float64)),\\\n",
    "                                                    [-1, numNerClasses]), axis=1)\n",
    "    \n",
    "    y_predicted_masked = tf.boolean_mask(y_predicted, mask)\n",
    "\n",
    "    return tf.reduce_mean(tf.cast(tf.equal(y_predicted_masked,y_label_masked) , dtype=tf.float64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer flatten_3 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "tf.Tensor(1.0, shape=(), dtype=float64)\n"
     ]
    }
   ],
   "source": [
    "y_true = tf.constant([[17],[0]])\n",
    "\n",
    "y_pred = tf.constant([\n",
    "    [0.6,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,.4,0,0,0],\n",
    "    [0.6,0.4,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],\n",
    "])\n",
    "\n",
    "\n",
    "print(custom_acc_orig_tokens(y_true, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again... correct! The false value for the '17' example is not considered.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lastly, define an Adam optimizer with new learning rate and beta parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "adam_customized = tf.keras.optimizers.Adam(lr=0.0005, beta_1=0.91, beta_2=0.999, epsilon=None, decay=0.1, amsgrad=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we define the summary statistics for TensorBoard. And then we can construct the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IV.2 Model Construction<a id=\"ner_model\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Time to build the model! Let's be pretty simple. No drop-out etc for now. But we re-train three BERT layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ner_model(max_input_length, train_layers, optimizer):\n",
    "    \"\"\"\n",
    "    Implementation of NER model\n",
    "    \n",
    "    variables:\n",
    "        max_input_length: number of tokens (max_length + 1)\n",
    "        train_layers: number of layers to be retrained\n",
    "        optimizer: optimizer to be used\n",
    "    \n",
    "    returns: model\n",
    "    \"\"\"\n",
    "    \n",
    "    in_id = tf.keras.layers.Input(shape=(max_length,), dtype='int32', name=\"input_ids\")\n",
    "    in_mask = tf.keras.layers.Input(shape=(max_length,), dtype='int32', name=\"input_masks\")\n",
    "    in_segment = tf.keras.layers.Input(shape=(max_length,), dtype='int32', name=\"segment_ids\")\n",
    "    \n",
    "    \n",
    "    bert_inputs = [in_id, in_mask, in_segment]\n",
    "    \n",
    "    \n",
    "    \n",
    "    # Note: Bert layer from Hugging Face returns two values: sequence ouput, and pooled output. Here, we only want\n",
    "    # the former. (See https://huggingface.co/transformers/model_doc/bert.html#tfbertmodel) \n",
    "    \n",
    "    bert_layer = TFBertModel.from_pretrained('bert-base-cased')\n",
    "    \n",
    "    # Freeze layers, i.e. only train number of layers specified, starting from the top\n",
    "    \n",
    "    retrain_layers = []\n",
    "    \n",
    "    for retrain_layer_number in range(train_layers):\n",
    "        \n",
    "        layer_code = '_' + str(11 - retrain_layer_number)\n",
    "        retrain_layers.append(layer_code)\n",
    "    \n",
    "    for w in bert_layer.weights:\n",
    "        if not any([x in w.name for x in retrain_layers]):\n",
    "            w._trainable = False\n",
    "            \n",
    "    # End of freezing section\n",
    "    \n",
    "    bert_sequence = bert_layer(bert_inputs)[0]\n",
    "    \n",
    "    print('Let us check the shape of the BERT layer output:', bert_sequence)\n",
    "    \n",
    "    dense = tf.keras.layers.Dense(256, activation='relu', name='dense')(bert_sequence)\n",
    "    \n",
    "    dense = tf.keras.layers.Dropout(rate=0.1)(dense)\n",
    "    \n",
    "    pred = tf.keras.layers.Dense(21, activation='softmax', name='ner')(dense)\n",
    "     \n",
    "    print('pred: ', pred)\n",
    "    \n",
    "    ## Prepare for multipe loss functions, although not used here\n",
    "    \n",
    "    losses = {\n",
    "        \"ner\": custom_loss,\n",
    "        }\n",
    "    lossWeights = {\"ner\": 1.0\n",
    "                  }\n",
    "    \n",
    "    model = tf.keras.models.Model(inputs=bert_inputs, outputs=pred)\n",
    "\n",
    "    model.compile(loss=losses, optimizer=optimizer, metrics=[custom_acc_orig_tokens, \n",
    "                                                          custom_acc_orig_non_other_tokens])\n",
    "    \n",
    "    \n",
    "    model.summary()\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## V. Model Runs/Experiments<a id=\"runs\"/>\n",
    "\n",
    "### V.1. With BERT-Layer Re-Training<a id=\"retrain\"/>\n",
    "\n",
    "It is time to run the first test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  101, 26159,  1104,  8568,  4487,  5067,  1138,  9639,  1194,\n",
       "        1498,  1106,  5641,  1103,  1594,  1107,  5008,  1105,  4555,\n",
       "        1103, 10602,  1104,  1418,  2830,  1121,  1115,  1583,   119,\n",
       "         102,     0,     0])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bert_inputs_train_k[0][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us choose to retrain the last six layers of BERT and then train the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Let us check the shape of the BERT layer output: Tensor(\"tf_bert_model/Identity:0\", shape=(None, 30, 768), dtype=float32)\n",
      "pred:  Tensor(\"ner/Identity:0\", shape=(None, 30, 21), dtype=float32)\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_ids (InputLayer)          [(None, 30)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_masks (InputLayer)        [(None, 30)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "segment_ids (InputLayer)        [(None, 30)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "tf_bert_model (TFBertModel)     ((None, 30, 768), (N 108310272   input_ids[0][0]                  \n",
      "                                                                 input_masks[0][0]                \n",
      "                                                                 segment_ids[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 30, 256)      196864      tf_bert_model[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_37 (Dropout)            (None, 30, 256)      0           dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "ner (Dense)                     (None, 30, 21)       5397        dropout_37[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 108,512,533\n",
      "Trainable params: 108,512,533\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Train on 33690 samples, validate on 14268 samples\n",
      "Epoch 1/8\n",
      "33690/33690 [==============================] - 292s 9ms/sample - loss: 0.1430 - custom_acc_orig_tokens: 0.9590 - custom_acc_orig_non_other_tokens: 0.7862 - val_loss: 0.1191 - val_custom_acc_orig_tokens: 0.9646 - val_custom_acc_orig_non_other_tokens: 0.8123\n",
      "Epoch 2/8\n",
      "33690/33690 [==============================] - 279s 8ms/sample - loss: 0.1196 - custom_acc_orig_tokens: 0.9644 - custom_acc_orig_non_other_tokens: 0.8120 - val_loss: 0.1155 - val_custom_acc_orig_tokens: 0.9655 - val_custom_acc_orig_non_other_tokens: 0.8214\n",
      "Epoch 3/8\n",
      "33690/33690 [==============================] - 279s 8ms/sample - loss: 0.1152 - custom_acc_orig_tokens: 0.9655 - custom_acc_orig_non_other_tokens: 0.8167 - val_loss: 0.1137 - val_custom_acc_orig_tokens: 0.9660 - val_custom_acc_orig_non_other_tokens: 0.8243\n",
      "Epoch 4/8\n",
      "33690/33690 [==============================] - 280s 8ms/sample - loss: 0.1130 - custom_acc_orig_tokens: 0.9659 - custom_acc_orig_non_other_tokens: 0.8201 - val_loss: 0.1124 - val_custom_acc_orig_tokens: 0.9664 - val_custom_acc_orig_non_other_tokens: 0.8256\n",
      "Epoch 5/8\n",
      "33690/33690 [==============================] - 280s 8ms/sample - loss: 0.1115 - custom_acc_orig_tokens: 0.9662 - custom_acc_orig_non_other_tokens: 0.8214 - val_loss: 0.1114 - val_custom_acc_orig_tokens: 0.9667 - val_custom_acc_orig_non_other_tokens: 0.8255\n",
      "Epoch 6/8\n",
      "33690/33690 [==============================] - 280s 8ms/sample - loss: 0.1103 - custom_acc_orig_tokens: 0.9664 - custom_acc_orig_non_other_tokens: 0.8226 - val_loss: 0.1107 - val_custom_acc_orig_tokens: 0.9668 - val_custom_acc_orig_non_other_tokens: 0.8272\n",
      "Epoch 7/8\n",
      "33690/33690 [==============================] - 279s 8ms/sample - loss: 0.1090 - custom_acc_orig_tokens: 0.9667 - custom_acc_orig_non_other_tokens: 0.8237 - val_loss: 0.1104 - val_custom_acc_orig_tokens: 0.9668 - val_custom_acc_orig_non_other_tokens: 0.8280\n",
      "Epoch 8/8\n",
      "33690/33690 [==============================] - 278s 8ms/sample - loss: 0.1084 - custom_acc_orig_tokens: 0.9669 - custom_acc_orig_non_other_tokens: 0.8250 - val_loss: 0.1098 - val_custom_acc_orig_tokens: 0.9671 - val_custom_acc_orig_non_other_tokens: 0.8277\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f599c5b0110>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)\n",
    "\n",
    "model = ner_model(max_length + 1, train_layers=6, optimizer = adam_customized)\n",
    "\n",
    "model.fit(\n",
    "    bert_inputs_train_k, \n",
    "    {\"ner\": labels_train_k },\n",
    "    validation_data=(bert_inputs_test_k, {\"ner\": labels_test_k }),\n",
    "    epochs=8,\n",
    "    batch_size=16\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**96.7% test accuracy for all original tokens and 82.8% for all original 'non-Other' tokens.... Not bad!!** And some tweaking and tuning should probably increase the values a bit more.\n",
    "\n",
    "Note that we used here the **Adam optimizer with custom values. Did that matter?** Why don't you try it...\n",
    "\n",
    "### V.2. Predictions & Confusion Matrix<a id=\"confusion\" />\n",
    "\n",
    "\n",
    "Let us look and see how well the model performs. We use the test here. (It probably would be better to split the data into train/validation/test, we are somewhat casual here).\n",
    "\n",
    "First, get all of the predictions for the test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_inputs_infer = [X_test[0], X_test[1], X_test[2]]\n",
    "\n",
    "result = model.predict(\n",
    "    bert_inputs_infer, \n",
    "    batch_size=16\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14268, 30, 21)\n"
     ]
    }
   ],
   "source": [
    "print(result.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the correct shape: # test sentences x sentence length x # classes. \n",
    "Let's get the prediction argmax for a random test sentence:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16  2 16 16 16  6 14 14 14\n",
      " 14 16 16 16 16 16]\n"
     ]
    }
   ],
   "source": [
    "print(np.argmax(result, axis=2)[6])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What were the labels?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17 16 20 20 16 20 16 16 16 16 16 16 16 16 16 16  2 16 20 16  6 14 20 14\n",
      " 14 16 19 18 18 18]\n"
     ]
    }
   ],
   "source": [
    "print(nerLabels_test[6])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Wrong? Correct!** Or.. is it?  \n",
    "\n",
    "**Question: Why are we not bothered by the first and the last 'mistakes', i.e., not identifying 20.17,19,18, etc.?**\n",
    "\n",
    "Let us now get the confusion matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_flat = [pred for preds in np.argmax(result, axis=2) for pred in preds]\n",
    "labels_flat = [label for labels in nerLabels_test for label in labels]\n",
    "\n",
    "clean_preds = []\n",
    "clean_labels = []\n",
    "\n",
    "for pred, label in zip(predictions_flat, labels_flat):\n",
    "    if label < 17:\n",
    "        clean_preds.append(pred)\n",
    "        clean_labels.append(label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = tf.math.confusion_matrix(\n",
    "    clean_labels,\n",
    "    clean_preds,\n",
    "    num_classes=None,\n",
    "    dtype=tf.dtypes.int32,\n",
    "    name=None,\n",
    "    weights=None\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Probably a little big and unbalanced to display. Let us focus on the rows/columns with the common labels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([     0,     28,  10481,   4166,     16,   4701,   4809,   4992,\n",
       "            0,     12,   1789,     26,      0,   3981,   5379,   1281,\n",
       "       228049])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(cm, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  8803     58    323    136     14     29     56    265]\n",
      " [   231   3945     39      5      0      6      5     14]\n",
      " [   771     69   3593    292     13    119    111    396]\n",
      " [   167      5    145   4017      0     43    227    151]\n",
      " [    89      0     12      6   4529      5      7    453]\n",
      " [    92      8    135     70      1   3118    336    356]\n",
      " [     3      3      9    131      1    107   4408     36]\n",
      " [   178     67    354    136    275    307    136 225922]]\n"
     ]
    }
   ],
   "source": [
    "cm_most = np.array(cm)[[2,3,5,6,7,13,14,16],:] [:, [2,3,5,6,7,13,14,16]]\n",
    "\n",
    "print(cm_most)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f58a9865a50>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(cm_most[:-1,:-1], cmap='Reds')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not bad!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### V.3 Without BERT-Layer Retraining (\"Did fine-tuning of BERT layers help?\")\n",
    "\n",
    "We will re-run the model, but without re-training of the top BERT layer: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Let us check the shape of the BERT layer output: Tensor(\"tf_bert_model_1/Identity:0\", shape=(None, 30, 768), dtype=float32)\n",
      "pred:  Tensor(\"ner_1/Identity:0\", shape=(None, 30, 21), dtype=float32)\n",
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_ids (InputLayer)          [(None, 30)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_masks (InputLayer)        [(None, 30)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "segment_ids (InputLayer)        [(None, 30)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "tf_bert_model_1 (TFBertModel)   ((None, 30, 768), (N 108310272   input_ids[0][0]                  \n",
      "                                                                 input_masks[0][0]                \n",
      "                                                                 segment_ids[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 30, 256)      196864      tf_bert_model_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_75 (Dropout)            (None, 30, 256)      0           dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "ner (Dense)                     (None, 30, 21)       5397        dropout_75[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 108,512,533\n",
      "Trainable params: 108,512,533\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Train on 33690 samples, validate on 14268 samples\n",
      "Epoch 1/8\n",
      "33690/33690 [==============================] - 174s 5ms/sample - loss: 0.1943 - custom_acc_orig_tokens: 0.9458 - custom_acc_orig_non_other_tokens: 0.7138 - val_loss: 0.1354 - val_custom_acc_orig_tokens: 0.9602 - val_custom_acc_orig_non_other_tokens: 0.7843\n",
      "Epoch 2/8\n",
      "33690/33690 [==============================] - 168s 5ms/sample - loss: 0.1387 - custom_acc_orig_tokens: 0.9587 - custom_acc_orig_non_other_tokens: 0.7804 - val_loss: 0.1252 - val_custom_acc_orig_tokens: 0.9624 - val_custom_acc_orig_non_other_tokens: 0.7979\n",
      "Epoch 3/8\n",
      "33690/33690 [==============================] - 168s 5ms/sample - loss: 0.1282 - custom_acc_orig_tokens: 0.9612 - custom_acc_orig_non_other_tokens: 0.7936 - val_loss: 0.1194 - val_custom_acc_orig_tokens: 0.9638 - val_custom_acc_orig_non_other_tokens: 0.8065\n",
      "Epoch 4/8\n",
      "33690/33690 [==============================] - 168s 5ms/sample - loss: 0.1216 - custom_acc_orig_tokens: 0.9625 - custom_acc_orig_non_other_tokens: 0.8006 - val_loss: 0.1168 - val_custom_acc_orig_tokens: 0.9644 - val_custom_acc_orig_non_other_tokens: 0.8081\n",
      "Epoch 5/8\n",
      "33690/33690 [==============================] - 168s 5ms/sample - loss: 0.1163 - custom_acc_orig_tokens: 0.9639 - custom_acc_orig_non_other_tokens: 0.8075 - val_loss: 0.1155 - val_custom_acc_orig_tokens: 0.9648 - val_custom_acc_orig_non_other_tokens: 0.8106\n",
      "Epoch 6/8\n",
      "33690/33690 [==============================] - 168s 5ms/sample - loss: 0.1126 - custom_acc_orig_tokens: 0.9648 - custom_acc_orig_non_other_tokens: 0.8124 - val_loss: 0.1151 - val_custom_acc_orig_tokens: 0.9650 - val_custom_acc_orig_non_other_tokens: 0.8118\n",
      "Epoch 7/8\n",
      "33690/33690 [==============================] - 167s 5ms/sample - loss: 0.1088 - custom_acc_orig_tokens: 0.9658 - custom_acc_orig_non_other_tokens: 0.8180 - val_loss: 0.1142 - val_custom_acc_orig_tokens: 0.9652 - val_custom_acc_orig_non_other_tokens: 0.8132\n",
      "Epoch 8/8\n",
      "33690/33690 [==============================] - 166s 5ms/sample - loss: 0.1060 - custom_acc_orig_tokens: 0.9663 - custom_acc_orig_non_other_tokens: 0.8203 - val_loss: 0.1146 - val_custom_acc_orig_tokens: 0.9649 - val_custom_acc_orig_non_other_tokens: 0.8204\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f58a8b47850>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = ner_model(max_length + 1,train_layers=0,optimizer='adam')\n",
    "\n",
    "# Instantiate variables\n",
    "\n",
    "model.fit(\n",
    "    bert_inputs_train_k, \n",
    "    {\"ner\": labels_train_k },\n",
    "    validation_data=(bert_inputs_test_k, {\"ner\": labels_test_k}),\n",
    "    epochs=8,\n",
    "    batch_size=32\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Close, but not quite as good.** - While one has to be careful given the different optimizer configurations and number of epochs, it looks as if not re-training BERT - in this case - increased the loss a bit. Let's call this **~96.5%/82.0%**.\n",
    "\n",
    "The relative benefit of fine-tuning BERT layers will depend on the problem.\n",
    "\n",
    "**Side Notes:** \n",
    " * Deeper re-training needs more compute resources\n",
    " * Deeper re-training often requires a tuned optimizer\n",
    " * Regularization is definitely important..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### V.4. A 90%-Reduced Training Set<a id=\"tiny\"/>\n",
    "\n",
    "\n",
    "The claim is that BERT is also very useful if one doesn't have much data. So let us see what happens if we cut the training data down to 10%. That leaves us with only ~3400 training examples. Not much..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 33690, 30)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "numTrainSentences = 3370\n",
    "\n",
    "bert_inputs_train_tiny = [bert_inputs_train_k[0][:numTrainSentences,:], \\\n",
    "                          bert_inputs_train_k[1][:numTrainSentences,:], \\\n",
    "                          bert_inputs_train_k[2][:numTrainSentences,:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_train_tiny = labels_train_k[:numTrainSentences,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Let us check the shape of the BERT layer output: Tensor(\"tf_bert_model_2/Identity:0\", shape=(None, 30, 768), dtype=float32)\n",
      "pred:  Tensor(\"ner_2/Identity:0\", shape=(None, 30, 21), dtype=float32)\n",
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_ids (InputLayer)          [(None, 30)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_masks (InputLayer)        [(None, 30)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "segment_ids (InputLayer)        [(None, 30)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "tf_bert_model_2 (TFBertModel)   ((None, 30, 768), (N 108310272   input_ids[0][0]                  \n",
      "                                                                 input_masks[0][0]                \n",
      "                                                                 segment_ids[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 30, 256)      196864      tf_bert_model_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_113 (Dropout)           (None, 30, 256)      0           dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "ner (Dense)                     (None, 30, 21)       5397        dropout_113[0][0]                \n",
      "==================================================================================================\n",
      "Total params: 108,512,533\n",
      "Trainable params: 108,512,533\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Train on 3370 samples, validate on 14268 samples\n",
      "Epoch 1/8\n",
      "3370/3370 [==============================] - 79s 23ms/sample - loss: 0.3054 - custom_acc_orig_tokens: 0.9214 - custom_acc_orig_non_other_tokens: 0.5506 - val_loss: 0.1898 - val_custom_acc_orig_tokens: 0.9450 - val_custom_acc_orig_non_other_tokens: 0.6999\n",
      "Epoch 2/8\n",
      "3370/3370 [==============================] - 71s 21ms/sample - loss: 0.1734 - custom_acc_orig_tokens: 0.9497 - custom_acc_orig_non_other_tokens: 0.7281 - val_loss: 0.1703 - val_custom_acc_orig_tokens: 0.9524 - val_custom_acc_orig_non_other_tokens: 0.7514\n",
      "Epoch 3/8\n",
      "3370/3370 [==============================] - 71s 21ms/sample - loss: 0.1511 - custom_acc_orig_tokens: 0.9545 - custom_acc_orig_non_other_tokens: 0.7526 - val_loss: 0.1625 - val_custom_acc_orig_tokens: 0.9545 - val_custom_acc_orig_non_other_tokens: 0.7613\n",
      "Epoch 4/8\n",
      "3370/3370 [==============================] - 71s 21ms/sample - loss: 0.1384 - custom_acc_orig_tokens: 0.9575 - custom_acc_orig_non_other_tokens: 0.7704 - val_loss: 0.1618 - val_custom_acc_orig_tokens: 0.9541 - val_custom_acc_orig_non_other_tokens: 0.7621\n",
      "Epoch 5/8\n",
      "3370/3370 [==============================] - 71s 21ms/sample - loss: 0.1265 - custom_acc_orig_tokens: 0.9610 - custom_acc_orig_non_other_tokens: 0.7882 - val_loss: 0.1615 - val_custom_acc_orig_tokens: 0.9543 - val_custom_acc_orig_non_other_tokens: 0.7631\n",
      "Epoch 6/8\n",
      "3370/3370 [==============================] - 71s 21ms/sample - loss: 0.1192 - custom_acc_orig_tokens: 0.9623 - custom_acc_orig_non_other_tokens: 0.7929 - val_loss: 0.1617 - val_custom_acc_orig_tokens: 0.9546 - val_custom_acc_orig_non_other_tokens: 0.7607\n",
      "Epoch 7/8\n",
      "3370/3370 [==============================] - 71s 21ms/sample - loss: 0.1081 - custom_acc_orig_tokens: 0.9652 - custom_acc_orig_non_other_tokens: 0.8126 - val_loss: 0.1613 - val_custom_acc_orig_tokens: 0.9552 - val_custom_acc_orig_non_other_tokens: 0.7600\n",
      "Epoch 8/8\n",
      "3370/3370 [==============================] - 71s 21ms/sample - loss: 0.1018 - custom_acc_orig_tokens: 0.9670 - custom_acc_orig_non_other_tokens: 0.8200 - val_loss: 0.1634 - val_custom_acc_orig_tokens: 0.9546 - val_custom_acc_orig_non_other_tokens: 0.7692\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f58eea7b6d0>"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = ner_model(max_length + 1,train_layers=0,optimizer='adam')\n",
    "\n",
    "model.fit(\n",
    "    bert_inputs_train_tiny, \n",
    "    {\"ner\": labels_train_tiny },\n",
    "    validation_data=(bert_inputs_test_k, {\"ner\": labels_test_k}),\n",
    "    epochs=8,\n",
    "    batch_size=16\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not too bad, one would think! **~95.5%/76.9%** on the test set, compared to ~96.5%/82.0% on the full training set with 10x the data! So BERT embeddings are serving quite well for a smaller data set. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VI. Summary<a id=\"summary\" />\n",
    "\n",
    "This finishes this cursory analysis of \"BERT for NER\". We pre-formatted our dataset, took care of tokenization and new inserted tokens (and labels!), defined a baseline model, and then - it would have been embarassing if we had failed - soundly beat the baseline with our Keras-based BERT+classification model. We saw that retraining of some BERT layers appeared to work well.  \n",
    "We also saw that even a small training set of about 3400 sentences did quite well using this architecture.\n",
    "\n",
    "All in all, we hope that this notebook was useful and despite its length reasonably readable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
